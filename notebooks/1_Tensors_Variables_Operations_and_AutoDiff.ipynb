{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Basics\n",
    "\n",
    "Here we introduce Tensors, Operations, Variables and Automatic Differentiation ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Tensors\n",
    "**Tensors** are multidimensional arrays. Each tensor has *shape* and *data* type property.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=0, shape=(), dtype=int8, numpy=1>,\n",
      " <tf.Tensor: id=1, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,\n",
      " <tf.Tensor: id=2, shape=(2, 2), dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "scaler = tf.constant(1, dtype=tf.int8)\n",
    "vector = tf.constant([1, 2, 3], dtype=tf.float32)\n",
    "matrix = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "\n",
    "pprint([scaler, vector, matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type convertion needs the `tf.cast` funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(2, 2), dtype=int8, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int8)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(matrix, dtype=tf.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `shape` property of a tensor and result from `tf.shape` function on a tensor is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(matrix))\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing tensors works pretty much as you would imagined with arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 4.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([3. 4.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, 1])\n",
    "print(matrix[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are handy functions to create special tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15, shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = tf.zeros((5, 4))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(5, 4), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.ones_like(o)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.51489913 0.14878559 0.87637496 0.16338205]\n",
      " [0.5680398  0.6436268  0.85502243 0.16321206]\n",
      " [0.15703404 0.23542702 0.26656926 0.20130396]\n",
      " [0.9828062  0.09003305 0.04659343 0.64389896]\n",
      " [0.40983427 0.8913517  0.30197513 0.29110909]], shape=(5, 4), dtype=float32)\n",
      "(5, 4)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform((5, 4))\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between numpy ndarrary and Tensor is pretty strightforwad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51489913 0.14878559 0.87637496 0.16338205]\n",
      " [0.5680398  0.6436268  0.85502243 0.16321206]\n",
      " [0.15703404 0.23542702 0.26656926 0.20130396]\n",
      " [0.9828062  0.09003305 0.04659343 0.64389896]\n",
      " [0.40983427 0.8913517  0.30197513 0.29110909]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.51489913 0.14878559 0.87637496 0.16338205]\n",
      " [0.5680398  0.6436268  0.85502243 0.16321206]\n",
      " [0.15703404 0.23542702 0.26656926 0.20130396]\n",
      " [0.9828062  0.09003305 0.04659343 0.64389896]\n",
      " [0.40983427 0.8913517  0.30197513 0.29110909]], shape=(5, 4), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "c = tf.convert_to_tensor(b)\n",
    "print(c)\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving Tensors between devices is also easy, well if you do have gpu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-db019b1b2704>:1: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.cpu()\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-129bf6fa397b>:1: _EagerTensorBase.gpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.gpu()\n",
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Operations \n",
    "\n",
    "They works pretty much as you'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33, shape=(5, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b == tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=38, shape=(5, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b == tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=45, shape=(5, 5), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ tf.transpose(b) == tf.matmul(a, b, transpose_b=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Variables  \n",
    "\n",
    "Tensors are immutable, they can't be updated. So, we need the updatable Tensors that is called `Variable` for parameters in the model. It works pretty much like Tensors, just updatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 4) dtype=float32, numpy=\n",
      "array([[0.51489913, 0.14878559, 0.87637496, 0.16338205],\n",
      "       [0.5680398 , 0.6436268 , 0.85502243, 0.16321206],\n",
      "       [0.15703404, 0.23542702, 0.26656926, 0.20130396],\n",
      "       [0.9828062 , 0.09003305, 0.04659343, 0.64389896],\n",
      "       [0.40983427, 0.8913517 , 0.30197513, 0.29110909]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(a)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=56, shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0.26512113, 0.02213715, 0.7680331 , 0.0266937 ],\n",
       "       [0.32266918, 0.41425547, 0.73106337, 0.02663818],\n",
       "       [0.02465969, 0.05542588, 0.07105917, 0.04052328],\n",
       "       [0.96590805, 0.00810595, 0.00217095, 0.4146059 ],\n",
       "       [0.16796413, 0.79450786, 0.09118898, 0.0847445 ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 4) dtype=float32, numpy=\n",
      "array([[0.26512113, 0.02213715, 0.7680331 , 0.0266937 ],\n",
      "       [0.32266918, 0.41425547, 0.73106337, 0.02663818],\n",
      "       [0.02465969, 0.05542588, 0.07105917, 0.04052328],\n",
      "       [0.96590805, 0.00810595, 0.00217095, 0.4146059 ],\n",
      "       [0.16796413, 0.79450786, 0.09118898, 0.0847445 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v.assign(tf.square(v))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 4) dtype=float32, numpy=\n",
      "array([[-0.7348789 , -0.97786283, -0.23196691, -0.9733063 ],\n",
      "       [-0.67733085, -0.5857445 , -0.26893663, -0.97336185],\n",
      "       [-0.9753403 , -0.9445741 , -0.92894083, -0.9594767 ],\n",
      "       [-0.03409195, -0.99189407, -0.9978291 , -0.58539414],\n",
      "       [-0.8320359 , -0.20549214, -0.90881103, -0.9152555 ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v.assign_sub(1 * tf.ones_like(v, dtype=tf.float32))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Automatic Differentiation \n",
    "\n",
    "Tensorflow can compute the partial derivatives of a computation with respect to the inputs for us. \n",
    "\n",
    "`tf.GradientTape` is a context in which all the operations around the variables are recorded. As a result, after the computation, we can ask if for the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=97, shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>,\n",
      " <tf.Tensor: id=104, shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "def f(a, b, d=3):\n",
    "    return tf.pow(a, 2) + d * b\n",
    "\n",
    "\n",
    "a = tf.Variable([4], dtype=tf.float32)\n",
    "b = tf.Variable([5], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    c = f(a, b)\n",
    "\n",
    "pprint(tape.gradient(c, [a, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default the context only keep track of `Variable`s. If you so wish to keep track of other stuff, you need just ask for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=126, shape=(), dtype=float32, numpy=5.0>]\n"
     ]
    }
   ],
   "source": [
    "d = tf.constant(3, dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(d)\n",
    "    c = f(a, b, d)\n",
    "\n",
    "pprint(tape.gradient(c, [d]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note the tape is not persistent, it will be deleted once used. Unless specificlly asked to be persistent. But then, you will need to mannually delete it to free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=144, shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GradientTape.gradient can only be called once on non-persistent tapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c3497d638d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \"\"\"\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[1;32m    966\u001b[0m                          \"non-persistent tapes.\")\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    c = f(a, b)\n",
    "\n",
    "print(tape.gradient(c, [a]))\n",
    "print(tape.gradient(c, [b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=166, shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>]\n",
      "[<tf.Tensor: id=188, shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    c = f(a, b)\n",
    "\n",
    "print(tape.gradient(c, [a]))\n",
    "print(tape.gradient(c, [b]))\n",
    "\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Linear Regression Example\n",
    "\n",
    "With all this we can start writing and training models already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_weights = tf.constant([1,2,3,4,5], dtype=tf.float32)[:, tf.newaxis]\n",
    "x = tf.constant(tf.random.uniform((5, 5)), dtype=tf.float32)\n",
    "y = tf.constant(x @ true_weights, dtype=tf.float32)\n",
    "\n",
    "weights = tf.Variable(tf.random.uniform((5, 1)), dtype=tf.float32)\n",
    "\n",
    "learning_rate = .5\n",
    "max_epochs = 1000\n",
    "\n",
    "\n",
    "def forward_pass(x, weights):\n",
    "    y_hat = x @ weights\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse loss at iteration 0 is 46.4647\n",
      "mse loss at iteration 100 is 0.0013\n",
      "mse loss at iteration 200 is 0.0002\n",
      "mse loss at iteration 300 is 0.0001\n",
      "mse loss at iteration 400 is 0.0000\n",
      "mse loss at iteration 500 is 0.0000\n",
      "mse loss at iteration 600 is 0.0000\n",
      "mse loss at iteration 700 is 0.0000\n",
      "mse loss at iteration 800 is 0.0000\n",
      "mse loss at iteration 900 is 0.0000\n"
     ]
    }
   ],
   "source": [
    "for it in range(max_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = forward_pass(x, weights)\n",
    "        loss = tf.reduce_mean(tf.square(y - y_hat))\n",
    "    if not (it % 100):\n",
    "        print('mse loss at iteration {} is {:5.4f}'.format(it, loss))\n",
    "    gradients = tape.gradient(loss, weights)\n",
    "    weights.assign_add(-learning_rate * gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(5, 1) dtype=float32, numpy=\n",
       "array([[1.0025035],\n",
       "       [1.9981416],\n",
       "       [3.0003157],\n",
       "       [3.9995728],\n",
       "       [5.000189 ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
